{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dcf48fb-ad55-4b1c-b5f8-cd6b588588fe",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "    1. Data Encoding from Image to Vector (juse euclidian?)\n",
    "    2. Transformer model to extract data info  https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ee115c-30ec-4da4-9b76-2b9a78836f24",
   "metadata": {},
   "source": [
    "# Import libs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fea78924-ea9d-4a45-a5ac-99ec4cf8634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Transformer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2667af33-fe06-4e86-a9aa-b5de69f39383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.SythData import SinusoidWaves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586f2561-f56d-4b77-a92e-f0c53ee049c4",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1390b4bd-4dcf-446b-ab41-4d5e757593b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SinusoidWaves(cps_number=40, length_data=1000, white_noise_level=\"min\").get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5658a3-a763-4a91-950d-2e85b77b3ae2",
   "metadata": {},
   "source": [
    "# Setup Transformer example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa4d8a9-2b35-473f-b723-326ccf0e141e",
   "metadata": {},
   "source": [
    "\n",
    "Parameters\n",
    "\n",
    "        d_model (int) – the number of expected features in the encoder/decoder inputs (default=512).\n",
    "\n",
    "        nhead (int) – the number of heads in the multiheadattention models (default=8).\n",
    "\n",
    "        num_encoder_layers (int) – the number of sub-encoder-layers in the encoder (default=6).\n",
    "\n",
    "        num_decoder_layers (int) – the number of sub-decoder-layers in the decoder (default=6).\n",
    "\n",
    "        dim_feedforward (int) – the dimension of the feedforward network model (default=2048).\n",
    "\n",
    "        dropout (float) – the dropout value (default=0.1).\n",
    "\n",
    "        activation (Union[str, Callable[[Tensor], Tensor]]) – the activation function of encoder/decoder intermediate layer, can be a string (“relu” or “gelu”) or a unary callable. Default: relu\n",
    "\n",
    "        custom_encoder (Optional[Any]) – custom encoder (default=None).\n",
    "\n",
    "        custom_decoder (Optional[Any]) – custom decoder (default=None).\n",
    "\n",
    "        layer_norm_eps (float) – the eps value in layer normalization components (default=1e-5).\n",
    "\n",
    "        batch_first (bool) – If True, then the input and output tensors are provided as (batch, seq, feature). Default: False (seq, batch, feature).\n",
    "\n",
    "        norm_first (bool) – if True, encoder and decoder layers will perform LayerNorms before other attention and feedforward operations, otherwise after. Default: False (after).\n",
    "\n",
    "        bias (bool) – If set to False, Linear and LayerNorm layers will not learn an additive bias. Default: True.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8028cd4-fe5a-40b0-83ac-2c080e672d3c",
   "metadata": {},
   "source": [
    ">>> transformer_model = nn.Transformer(nhead=16, num_encoder_layers=12)\n",
    ">>> src = torch.rand((10, 32, 512))\n",
    ">>> tgt = torch.rand((20, 32, 512))\n",
    ">>> out = transformer_model(src, tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efa67cae-fdf1-42ae-abdb-a25b85cddb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transformer = Transformer(\n",
    "                           d_model=100,\n",
    "                           nhead=4,\n",
    "                           num_encoder_layers=4,\n",
    "                           num_decoder_layers=4,\n",
    "                           dim_feedforward=1024,\n",
    "                           dropout=0.1,\n",
    "                           activation='relu',\n",
    "                           batch_first=True,\n",
    "                           norm_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2de658f-b11e-4e14-885c-e5e0bdbd82f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = torch.rand((10, 100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7efbc07c-8fd1-4006-93eb-5561ede4fef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt = torch.rand((10, 100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "816c61e8-3b0d-4925-9fda-0ab12717d6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 100, 100])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_transformer(src, tgt).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd6cca7-cc30-449a-91f0-92480a3e178e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
